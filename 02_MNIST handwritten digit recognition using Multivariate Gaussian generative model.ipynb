{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Handwritten digit recognition using a Gaussian Generative Model\n",
    "\n",
    "The solution has the following parts:\n",
    "\n",
    "1. Load the data\n",
    "2. Prepare the data by splitting the train data into training set and validation set\n",
    "3. Create a classifier routine using multinomial_normal function\n",
    "4. Iterate over several smoothing factor to land at the best smoothing factor on the validation set\n",
    "5. Apply the best smoothing factor on the test data set and calculate the accuracy\n",
    "6. Display a few misclassified digits and their posterior probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Deepthi/Documents/DSE/DSE210 - Statistics and Probability/Day 3/Assignment/Data\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/Deepthi/Documents/DSE/DSE210 - Statistics and Probability/Day 3/Assignment/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from struct import unpack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split;\n",
    "import math \n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The functions used to import the data and display the digits\n",
    "\n",
    "# %load loader.py\n",
    "def loadmnist(imagefile, labelfile):\n",
    "\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = open(imagefile, 'rb')\n",
    "    labels = open(labelfile, 'rb')\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    # Get data\n",
    "    x = np.zeros((N, rows*cols), dtype=np.uint8)  # Initialize numpy array\n",
    "    y = np.zeros(N, dtype=np.uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        for j in range(rows*cols):\n",
    "            tmp_pixel = images.read(1)  # Just a single byte\n",
    "            tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "            x[i][j] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "\n",
    "    images.close()\n",
    "    labels.close()\n",
    "    return (x, y)\n",
    "\n",
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train_images, train_labels = loadmnist('train-images-idx3-ubyte','train-labels-idx1-ubyte')\n",
    "test_images, test_labels = loadmnist('t10k-images-idx3-ubyte','t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data by splitting the train data into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train data into train and validation sets\n",
    "train_set,validation_set, train_label, validation_label = train_test_split(train_images,train_labels, test_size=10000, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5632, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_set[np.where(train_label==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a classifier routine using multinomial_normal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to determine the clas probabilities, calculate mean and cov and fit a gaussian\n",
    "def classifier(c,data_set,label_set):\n",
    "    label = []\n",
    "    pd = []\n",
    "    for i in range(0,10):\n",
    "        priors = len(train_set[np.where(train_label==i)])/float(len(train_set))\n",
    "        Mean = train_set[np.where(train_label==i)].mean(0)\n",
    "        Cov = np.cov((train_set[np.where(train_label==i)]).T)\n",
    "        Cov = Cov + (c*np.identity(784))\n",
    "        px = multivariate_normal(mean=Mean, cov=Cov) \n",
    "        pd.append(np.log(priors) + px.logpdf(data_set))\n",
    "    max_prob = np.argmax(pd, axis = 0)\n",
    "    error = np.sum([i!=j for i,j in zip(max_prob, label_set)])*100/(len(label_set)*1.0)\n",
    "    accuracy = 100- (np.sum([i!=j for i,j in zip(max_prob, label_set)])*100/(len(label_set)*1.0))\n",
    "    return c, error, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over several smoothing factor to land at the best smoothing factor on the validation set\n",
    "\n",
    "To obtain optimum smoothing factor:\n",
    "\n",
    "1. First try in steps of 1000 to determine the most optimum zone (The zone in which you achieve best accuracy)\n",
    "2. Repeat the same in steps of 100, 10 and then 1 to land on the most optimum smoothing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5.3399999999999999, 94.659999999999997)\n",
      "(2000, 4.8799999999999999, 95.120000000000005)\n",
      "(3000, 4.8499999999999996, 95.150000000000006)\n",
      "(4000, 5.04, 94.959999999999994)\n",
      "(5000, 5.0499999999999998, 94.950000000000003)\n",
      "(6000, 5.1100000000000003, 94.890000000000001)\n",
      "(7000, 5.2000000000000002, 94.799999999999997)\n",
      "(8000, 5.2599999999999998, 94.739999999999995)\n",
      "(9000, 5.4000000000000004, 94.599999999999994)\n",
      "(10000, 5.5800000000000001, 94.420000000000002)\n",
      "(11000, 5.7699999999999996, 94.230000000000004)\n",
      "(12000, 6.0300000000000002, 93.969999999999999)\n",
      "(13000, 6.1399999999999997, 93.859999999999999)\n",
      "(14000, 6.2400000000000002, 93.760000000000005)\n"
     ]
    }
   ],
   "source": [
    "# Go in steps of 1000 from 1000 to 15000:\n",
    "for c in np.arange(1000,15000,1000):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4.8799999999999999, 95.120000000000005)\n",
      "(2100, 4.8499999999999996, 95.150000000000006)\n",
      "(2200, 4.8600000000000003, 95.140000000000001)\n",
      "(2300, 4.8499999999999996, 95.150000000000006)\n",
      "(2400, 4.8600000000000003, 95.140000000000001)\n",
      "(2500, 4.8499999999999996, 95.150000000000006)\n",
      "(2600, 4.8300000000000001, 95.170000000000002)\n",
      "(2700, 4.8399999999999999, 95.159999999999997)\n",
      "(2800, 4.8700000000000001, 95.129999999999995)\n",
      "(2900, 4.8300000000000001, 95.170000000000002)\n",
      "(3000, 4.8499999999999996, 95.150000000000006)\n",
      "(3100, 4.8700000000000001, 95.129999999999995)\n",
      "(3200, 4.9199999999999999, 95.079999999999998)\n",
      "(3300, 4.9500000000000002, 95.049999999999997)\n",
      "(3400, 4.96, 95.040000000000006)\n",
      "(3500, 4.9400000000000004, 95.060000000000002)\n",
      "(3600, 4.9900000000000002, 95.010000000000005)\n",
      "(3700, 5.0099999999999998, 94.989999999999995)\n",
      "(3800, 5.0499999999999998, 94.950000000000003)\n",
      "(3900, 5.0300000000000002, 94.969999999999999)\n"
     ]
    }
   ],
   "source": [
    "## Consider 2000 to 4000 in steps of 100\n",
    "for c in np.arange(2000,4000,100):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 4.8499999999999996, 95.150000000000006)\n",
      "(2510, 4.8499999999999996, 95.150000000000006)\n",
      "(2520, 4.8600000000000003, 95.140000000000001)\n",
      "(2530, 4.8499999999999996, 95.150000000000006)\n",
      "(2540, 4.8499999999999996, 95.150000000000006)\n",
      "(2550, 4.8499999999999996, 95.150000000000006)\n",
      "(2560, 4.8399999999999999, 95.159999999999997)\n",
      "(2570, 4.8399999999999999, 95.159999999999997)\n",
      "(2580, 4.8399999999999999, 95.159999999999997)\n",
      "(2590, 4.8300000000000001, 95.170000000000002)\n",
      "(2600, 4.8300000000000001, 95.170000000000002)\n",
      "(2610, 4.8300000000000001, 95.170000000000002)\n",
      "(2620, 4.8200000000000003, 95.180000000000007)\n",
      "(2630, 4.8200000000000003, 95.180000000000007)\n",
      "(2640, 4.8200000000000003, 95.180000000000007)\n",
      "(2650, 4.8200000000000003, 95.180000000000007)\n",
      "(2660, 4.8300000000000001, 95.170000000000002)\n",
      "(2670, 4.8399999999999999, 95.159999999999997)\n",
      "(2680, 4.8399999999999999, 95.159999999999997)\n",
      "(2690, 4.8399999999999999, 95.159999999999997)\n"
     ]
    }
   ],
   "source": [
    "## Consider 2500 to 2700 in steps of 10\n",
    "for c in np.arange(2500,2700,10):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 4.8300000000000001, 95.170000000000002)\n",
      "(2611, 4.8300000000000001, 95.170000000000002)\n",
      "(2612, 4.8300000000000001, 95.170000000000002)\n",
      "(2613, 4.8200000000000003, 95.180000000000007)\n",
      "(2614, 4.8200000000000003, 95.180000000000007)\n",
      "(2615, 4.8200000000000003, 95.180000000000007)\n",
      "(2616, 4.8200000000000003, 95.180000000000007)\n",
      "(2617, 4.8200000000000003, 95.180000000000007)\n",
      "(2618, 4.8200000000000003, 95.180000000000007)\n",
      "(2619, 4.8200000000000003, 95.180000000000007)\n",
      "(2620, 4.8200000000000003, 95.180000000000007)\n",
      "(2621, 4.8200000000000003, 95.180000000000007)\n",
      "(2622, 4.8200000000000003, 95.180000000000007)\n",
      "(2623, 4.8200000000000003, 95.180000000000007)\n",
      "(2624, 4.8200000000000003, 95.180000000000007)\n",
      "(2625, 4.8200000000000003, 95.180000000000007)\n",
      "(2626, 4.8200000000000003, 95.180000000000007)\n",
      "(2627, 4.8200000000000003, 95.180000000000007)\n",
      "(2628, 4.8200000000000003, 95.180000000000007)\n",
      "(2629, 4.8200000000000003, 95.180000000000007)\n",
      "(2630, 4.8200000000000003, 95.180000000000007)\n",
      "(2631, 4.8200000000000003, 95.180000000000007)\n",
      "(2632, 4.8200000000000003, 95.180000000000007)\n",
      "(2633, 4.8200000000000003, 95.180000000000007)\n",
      "(2634, 4.8200000000000003, 95.180000000000007)\n",
      "(2635, 4.8200000000000003, 95.180000000000007)\n",
      "(2636, 4.8200000000000003, 95.180000000000007)\n",
      "(2637, 4.8200000000000003, 95.180000000000007)\n",
      "(2638, 4.8200000000000003, 95.180000000000007)\n",
      "(2639, 4.8200000000000003, 95.180000000000007)\n",
      "(2640, 4.8200000000000003, 95.180000000000007)\n",
      "(2641, 4.8200000000000003, 95.180000000000007)\n",
      "(2642, 4.8200000000000003, 95.180000000000007)\n",
      "(2643, 4.8200000000000003, 95.180000000000007)\n",
      "(2644, 4.8200000000000003, 95.180000000000007)\n",
      "(2645, 4.8200000000000003, 95.180000000000007)\n",
      "(2646, 4.8200000000000003, 95.180000000000007)\n",
      "(2647, 4.8200000000000003, 95.180000000000007)\n",
      "(2648, 4.8200000000000003, 95.180000000000007)\n",
      "(2649, 4.8200000000000003, 95.180000000000007)\n",
      "(2650, 4.8200000000000003, 95.180000000000007)\n",
      "(2651, 4.8300000000000001, 95.170000000000002)\n",
      "(2652, 4.8300000000000001, 95.170000000000002)\n",
      "(2653, 4.8300000000000001, 95.170000000000002)\n",
      "(2654, 4.8300000000000001, 95.170000000000002)\n",
      "(2655, 4.8300000000000001, 95.170000000000002)\n",
      "(2656, 4.8300000000000001, 95.170000000000002)\n",
      "(2657, 4.8300000000000001, 95.170000000000002)\n",
      "(2658, 4.8300000000000001, 95.170000000000002)\n",
      "(2659, 4.8300000000000001, 95.170000000000002)\n"
     ]
    }
   ],
   "source": [
    "## Consider 2610 to 2660 in steps of 1\n",
    "for c in np.arange(2610,2660,1):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2613, 4.8200000000000003, 95.180000000000007)\n"
     ]
    }
   ],
   "source": [
    "## Test the the optimum smoothing value on validation set\n",
    "print classifier(2613,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the best smoothing factor on the test data set and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2613, 4.3099999999999996, 95.689999999999998)\n"
     ]
    }
   ],
   "source": [
    "## Apply the classifier on the test data to understand the accuracy\n",
    "print classifier(2613,test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a few misclassified digits and their posterior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Modify the function to get the misclassified digits\n",
    "def classifier2(c,data_set,label_set):\n",
    "    label = []\n",
    "    pd = []\n",
    "    for i in range(0,10):\n",
    "        priors = len(train_set[np.where(train_label==i)])/float(len(train_set))\n",
    "        Mean = train_set[np.where(train_label==i)].mean(0)\n",
    "        Cov = np.cov((train_set[np.where(train_label==i)]).T)\n",
    "        Cov = Cov + (c*np.identity(784))\n",
    "        px = multivariate_normal(mean=Mean, cov=Cov) \n",
    "        pd.append(np.log(priors) + px.logpdf(data_set))\n",
    "    max_prob = np.argmax(pd, axis = 0)\n",
    "    output = zip(max_prob, label_set)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAB2CAYAAACNkUn3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyu/PNh2RtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11534d850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Disply 5 misclassified digits\n",
    "get_error = classifier2(2613,test_images, test_labels)\n",
    "indexes = [i for i,x in enumerate(get_error) if x[0]!=x[1]]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "error = [x[0] for x in get_error if x[0]!=x[1]][:5]\n",
    "for i in range(0,5):    \n",
    "    j=i+1\n",
    "    plt.subplot(1,5,j)\n",
    "    displaychar(test_images[indexes][i])\n",
    "    plt.title('Classified as: %i' %error[i],fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Modify the function to get the posterior probabilites\n",
    "def classifier3(c,data_set,label_set):\n",
    "    label = []\n",
    "    pd = []\n",
    "    for i in range(0,10):\n",
    "        priors = len(train_set[np.where(train_label==i)])/float(len(train_set))\n",
    "        Mean = train_set[np.where(train_label==i)].mean(0)\n",
    "        Cov = np.cov((train_set[np.where(train_label==i)]).T)\n",
    "        Cov = Cov + (c*np.identity(784))\n",
    "        px = multivariate_normal(mean=Mean, cov=Cov) \n",
    "        pd.append(np.log(priors) + px.logpdf(data_set))\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>1</th>\n",
       "      <th>8</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4117.430362</td>\n",
       "      <td>-4146.336160</td>\n",
       "      <td>-4085.897114</td>\n",
       "      <td>-4175.782530</td>\n",
       "      <td>-4038.433573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4093.636764</td>\n",
       "      <td>-4209.643728</td>\n",
       "      <td>-3944.258061</td>\n",
       "      <td>-4508.859618</td>\n",
       "      <td>-3939.713184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4064.229417</td>\n",
       "      <td>-4127.645399</td>\n",
       "      <td>-4012.276470</td>\n",
       "      <td>-4123.686823</td>\n",
       "      <td>-4016.491972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4055.283783</td>\n",
       "      <td>-4081.336775</td>\n",
       "      <td>-4025.623356</td>\n",
       "      <td>-4118.177712</td>\n",
       "      <td>-4006.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4049.941278</td>\n",
       "      <td>-4019.943563</td>\n",
       "      <td>-3997.440303</td>\n",
       "      <td>-4136.515091</td>\n",
       "      <td>-3979.879773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4094.544227</td>\n",
       "      <td>-4068.892838</td>\n",
       "      <td>-4062.439011</td>\n",
       "      <td>-4121.957813</td>\n",
       "      <td>-4024.308730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4204.697137</td>\n",
       "      <td>-4213.617167</td>\n",
       "      <td>-4106.876718</td>\n",
       "      <td>-4302.838998</td>\n",
       "      <td>-4045.429547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3980.364376</td>\n",
       "      <td>-3978.539522</td>\n",
       "      <td>-3953.658101</td>\n",
       "      <td>-4229.448893</td>\n",
       "      <td>-3948.761389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4012.334025</td>\n",
       "      <td>-4066.604205</td>\n",
       "      <td>-3987.437770</td>\n",
       "      <td>-4087.108364</td>\n",
       "      <td>-3992.723826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3986.706096</td>\n",
       "      <td>-3976.656389</td>\n",
       "      <td>-3978.935285</td>\n",
       "      <td>-4118.596574</td>\n",
       "      <td>-3950.305978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7            9            1            8            1\n",
       "0 -4117.430362 -4146.336160 -4085.897114 -4175.782530 -4038.433573\n",
       "1 -4093.636764 -4209.643728 -3944.258061 -4508.859618 -3939.713184\n",
       "2 -4064.229417 -4127.645399 -4012.276470 -4123.686823 -4016.491972\n",
       "3 -4055.283783 -4081.336775 -4025.623356 -4118.177712 -4006.003211\n",
       "4 -4049.941278 -4019.943563 -3997.440303 -4136.515091 -3979.879773\n",
       "5 -4094.544227 -4068.892838 -4062.439011 -4121.957813 -4024.308730\n",
       "6 -4204.697137 -4213.617167 -4106.876718 -4302.838998 -4045.429547\n",
       "7 -3980.364376 -3978.539522 -3953.658101 -4229.448893 -3948.761389\n",
       "8 -4012.334025 -4066.604205 -3987.437770 -4087.108364 -3992.723826\n",
       "9 -3986.706096 -3976.656389 -3978.935285 -4118.596574 -3950.305978"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display posterior probabilities\n",
    "probabilities = classifier3(2613,test_images, test_labels)\n",
    "probabilities2 = np.vstack(probabilities).T ## Convert to np array\n",
    "probabilities3 = probabilities2[indexes][:5].T ## Get the 5 misclassified numbers\n",
    "posterior = pd.DataFrame(probabilities3)\n",
    "posterior.columns = error\n",
    "posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
